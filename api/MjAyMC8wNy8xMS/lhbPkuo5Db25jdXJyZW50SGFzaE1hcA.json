{"title":"关于ConcurrentHashMap","date":"2020-07-11T07:11:46.000Z","date_formatted":{"ll":"2020年7月11日","L":"2020/07/11","MM-DD":"07-11"},"link":"2020/07/11/关于ConcurrentHashMap","tags":["Java集合"],"updated":"2020-07-11T08:53:01.429Z","content":"<h1 id=\"关于concurrenthashmap\">关于ConcurrentHashMap<a href=\"#关于concurrenthashmap\" title=\"关于ConcurrentHashMap\"></a></h1><h2 id=\"concurrenthashmap如何保证线程安全？\">ConcurrentHashMap如何保证线程安全？<a href=\"#concurrenthashmap如何保证线程安全？\" title=\"ConcurrentHashMap如何保证线程安全？\"></a></h2><h3 id=\"jdk17\">JDK1.7<a href=\"#jdk17\" title=\"JDK1.7\"></a></h3><p>Segment数组+HashEntry数组+链表。Segment继承了ReentrantLock，所以Segment扮演了可重入锁的角色。一个ConcurrentHashMap包含一个Segment数组，一个Segment包含一个HashEntry数组。当对HashEntry数组的数据进行修改时，只获得对应的Segment的锁。多个线程访问不同Segment的数据，就不会存在锁竞争，相比HashTable锁全表，提高并发效率。</p>\n<h3 id=\"jdk18\">JDK1.8<a href=\"#jdk18\" title=\"JDK1.8\"></a></h3><p>采用Node数组+链表/红黑树，使用synchronized和CAS保证并发安全。</p>\n<h2 id=\"锁粒度？\">锁粒度？<a href=\"#锁粒度？\" title=\"锁粒度？\"></a></h2><ul><li>在JDK1.7版本，锁的粒度是Segment；在JDK1.8版本，锁的粒度是Node节点，锁的粒度降低了。</li>\n<li>用synchronized代替ReentrantLock。在锁的粒度低到这种程度的情况下，出现并发争抢的可能性也降低了。哪怕发生了争抢，自旋几十次就能拿到锁，那么synchronized就不会升级到重量级锁，等待的线程就不用挂起，这就减少了挂起唤醒这个上下文切换的过程开销。</li>\n</ul><h2 id=\"扩容\">扩容<a href=\"#扩容\" title=\"扩容\"></a></h2><blockquote>\n<p>1、根据当前数组长度n，新建一个两倍长度的数组<code>nextTable</code>；</p>\n<p>2、初始化<code>ForwardingNode</code>节点，其中保存了新数组<code>nextTable</code>的引用，在处理完每个槽位的节点之后当做占位节点，表示该槽位已经处理过了；</p>\n<p>3、通过<code>for</code>自循环处理每个槽位中的链表元素，默认<code>advace</code>为真，通过CAS设置<code>transferIndex</code>属性值，并初始化<code>i</code>和<code>bound</code>值，<code>i</code>指当前处理的槽位序号，<code>bound</code>指需要处理的槽位边界;</p>\n<p>4、在当前假设条件下，槽位a中没有节点，则通过CAS插入在第二步中初始化的<code>ForwardingNode</code>节点，用于告诉其它线程该槽位已经处理过了；</p>\n<p>5、如果槽位a已经被线程A处理了，那么线程B处理到这个节点时，取到该节点的hash值应该为<code>MOVED</code>，值为<code>-1</code>，则直接跳过，继续处理下一个槽位b的节点；</p>\n<p>6、处理槽位b的节点，是一个链表结构，先定义两个变量节点<code>ln</code>和<code>hn</code>，按我的理解应该是<code>lowNode</code>和<code>highNode</code>，分别保存hash值的第X位为0和1的节点，具体实现如下：使用<code>fn&amp;n</code>可以快速把链表中的元素区分成两类，A类是hash值的第X位为0，B类是hash值的第X位为1，并通过<code>lastRun</code>记录最后需要处理的节点.，通过CAS把ln链表设置到新数组的i位置，hn链表设置到i+n的位置；（见QA）</p>\n<p>7、如果该槽位是红黑树结构，则构造树节点<code>lo</code>和<code>hi</code>，遍历红黑树中的节点，同样根据<code>hash&amp;n</code>算法，把节点分为两类，分别插入到<code>lo</code>和<code>hi</code>为头的链表中，根据<code>lo</code>和<code>hi</code>链表中的元素个数分别生成<code>ln</code>和<code>hn</code>节点，其中<code>ln</code>节点的生成逻辑如下：<br> （1）如果<code>lo</code>链表的元素个数小于等于<code>UNTREEIFY_THRESHOLD</code>，默认为6，则通过<code>untreeify</code>方法把树节点链表转化成普通节点链表；<br> （2）否则判断<code>hi</code>链表中的元素个数是否等于0：如果等于0，表示<code>lo</code>链表中包含了所有原始节点，则设置原始红黑树给<code>ln</code>，否则根据<code>lo</code>链表重新构造红黑树。</p>\n<p>最后，同样的通过CAS把<code>ln</code>设置到新数组的<code>i</code>位置，<code>hn</code>设置到<code>i+n</code>位置。</p>\n<p>Q : JDK1.8扩容后 ln 和 hn 链不用经过 hash 取模运算，分别被直接放置在新数组的 i 和 n + i 的位置上，那么如何保证这种方式依旧可以用过 h &amp; (n - 1) 正确算出 hash 桶的位置？</p>\n<p>A : 如果 fh &amp; n-1 = i ，那么扩容之后的 hash 计算方法应该是 fh &amp; 2n-1 。 因为 n 是 2 的幂次方数，所以 如果 n=16， n-1 就是 1111(二进制)， 那么 2n-1 就是 11111 (二进制) 。 其实 fh &amp; 2n-1 和 fh &amp; n-1 的值区别就在于多出来的那个 1 =&gt; fh &amp; (10000) 这个就是两个 hash 的区别所在 。而 10000 就是 n 。所以说 如果 fh 的第五 bit 不是 1 的话 fh &amp; n = 0 =&gt; fh &amp; 2n-1 == fh &amp; n-1 = i 。 如果第5位是 1 的话 。fh &amp; n = n =&gt; fh &amp; 2n-1 = i+n 。</p>\n</blockquote>\n<h2 id=\"size\">size()<a href=\"#size\" title=\"size()\"></a></h2><ul><li>1.7中，刚一开始不加锁，前后计算两次所有segment里面的数量大小和，两次结果相等，表明没有新的元素加入，计算的结果是正确的。如果不相等，就对每个segment加锁，再进行计算，返回结果并释放锁。</li>\n<li>1.8中，推荐用mappingCount方法获取size，返回值为long。主要调用sumCount方法。<ul><li>属性有baseCount和counterCells。</li>\n<li>baseCount是一个 volatile 的变量，在 addCount 方法中会使用它，而 addCount 方法在 put 结束后会调用。在 addCount 方法中，会对这个变量做 CAS 加法。</li>\n<li>CounterCell是一种用于分配计数的填充单元，使用了 @sun.misc.Contended （防止伪共享）标记的类，内部一个 volatile 变量。</li>\n<li>在没有并发的情况下，使用一个 baseCount volatile 变量就足够了，当并发的时候，CAS 修改 baseCount 失败后，就会使用 CounterCell 类了，会创建一个这个对象，通常对象的 volatile value 属性是 1。在计算 size 的时候，会将 baseCount 和 CounterCell 数组中的元素的 value 累加，得到总的大小。</li>\n</ul></li>\n</ul>","prev":{"title":"关于Java内存区域","link":"2020/07/11/关于Java内存区域"},"next":{"title":"Tiny-Spring","link":"2020/06/19/tiny-spring"},"plink":"https://cxccao.github.io/2020/07/11/关于ConcurrentHashMap/","toc":[{"id":"关于concurrenthashmap","title":"关于ConcurrentHashMap","index":"1","children":[{"id":"concurrenthashmap如何保证线程安全？","title":"ConcurrentHashMap如何保证线程安全？","index":"1.1","children":[{"id":"jdk17","title":"JDK1.7","index":"1.1.1"},{"id":"jdk18","title":"JDK1.8","index":"1.1.2"}]},{"id":"锁粒度？","title":"锁粒度？","index":"1.2"},{"id":"扩容","title":"扩容","index":"1.3"},{"id":"size","title":"size()","index":"1.4"}]}],"copyright":{"author":"Shelton Chen","link":"<a href=\"https://cxccao.github.io/2020/07/11/关于ConcurrentHashMap/\" title=\"关于ConcurrentHashMap\">https://cxccao.github.io/2020/07/11/关于ConcurrentHashMap/</a>","updated":"2020年7月11日","license":"署名-非商业性使用-相同方式共享 4.0 国际 (<a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\" rel=\\\"external nofollow\\\" target=\\\"_blank\\\">CC BY-NC-ND 4.0</a>)"}}