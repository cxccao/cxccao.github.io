{"title":"关于ConcurrentHashMap","date":"2020-07-11T07:11:46.000Z","date_formatted":{"ll":"2020年7月11日","L":"2020/07/11","MM-DD":"07-11"},"link":"2020/07/11/关于ConcurrentHashMap","tags":["Java集合"],"updated":"2020-07-29T10:07:30.745Z","content":"<h1 id=\"关于concurrenthashmap\">关于ConcurrentHashMap<a href=\"#关于concurrenthashmap\" title=\"关于ConcurrentHashMap\"></a></h1><h2 id=\"先聊聊hashmap\">先聊聊HashMap<a href=\"#先聊聊hashmap\" title=\"先聊聊HashMap\"></a></h2><h3 id=\"结构\">结构<a href=\"#结构\" title=\"结构\"></a></h3><p>key 通过 hashcode 经过扰动函数处理得到 hash 值，通过 (n - 1) &amp; hash 判断当前元素存放的位置。</p>\n<ul><li>JDK1.7：HahsEntry 数组 + 链表</li>\n<li>JDK1.8：Node 数组 + 链表 / 红黑树· 方法</li>\n</ul><h3 id=\"put方法\">put方法<a href=\"#put方法\" title=\"put方法\"></a></h3><ol><li>判断数组 table 是否为空或 null，是则扩容。</li>\n<li>计算 hash 所在下标 i 的位置是否为 null，是则直接新建节点。</li>\n<li>判断 table[i] 的首节点 p 是否和 key 一样（hash、key、equals），是则覆盖 value。</li>\n<li>判断 p 是否为树节点，是则调用红黑树的插入方法。</li>\n<li>遍历链表，若 key 不存在，则尾插，若节点数量达到阈值，则转化红黑树；若 key 存在，跳出循环。</li>\n<li>表示找到 key 相同节点，覆盖 value。</li>\n<li>判断键值对数量 size 是否超过最大容量，是则扩容。</li>\n</ol><h3 id=\"get方法\">get方法<a href=\"#get方法\" title=\"get方法\"></a></h3><ol><li>判断 table 非空或非 null。</li>\n<li>判断 table[i] 首节点是否和 key一样，是则返回 value。</li>\n<li>判断是否为红黑树，是则按红黑树的查找方法，否则遍历链表。</li>\n</ol><h3 id=\"resize方法\">resize方法<a href=\"#resize方法\" title=\"resize方法\"></a></h3><ol><li>如果 table 为 null，则生成空的 table 返回。</li>\n<li>不为空，计算新 table 长度为原来2倍。</li>\n<li>遍历 oldTable<ol><li>首节点为空，跳出循环</li>\n<li>无后续节点，重新计算 hash 位，跳出循环</li>\n<li>当前是红黑树，调用红黑树重定位</li>\n<li>当前是链表，（e.hash &amp; oldCap）== 0 判断是否需要移位，相等的话原位，不相等则移到 当前位 + oldCap 的位置。</li>\n</ol></li>\n</ol><h2 id=\"concurrenthashmap如何保证线程安全？\">ConcurrentHashMap如何保证线程安全？<a href=\"#concurrenthashmap如何保证线程安全？\" title=\"ConcurrentHashMap如何保证线程安全？\"></a></h2><h3 id=\"jdk17\">JDK1.7<a href=\"#jdk17\" title=\"JDK1.7\"></a></h3><p>Segment 数组 + HashEntry 数组 + 链表。Segment 继承了 ReentrantLock，所以Segment 扮演了可重入锁的角色。一个 ConcurrentHashMap 包含一个 Segment 数组，一个 Segment 包含一个 HashEntry 数组。当对 HashEntry 数组的数据进行修改时，只获得对应的 Segment 的锁。多个线程访问不同 Segment 的数据，就不会存在锁竞争，相比 HashTable 锁全表，提高并发效率。</p>\n<h3 id=\"jdk18\">JDK1.8<a href=\"#jdk18\" title=\"JDK1.8\"></a></h3><p>采用 Node 数组+链表/红黑树，使用 synchronized 和 CAS 保证并发安全。</p>\n<h2 id=\"锁粒度？\">锁粒度？<a href=\"#锁粒度？\" title=\"锁粒度？\"></a></h2><ul><li>在 JDK1.7 版本，锁的粒度是 Segment；在 JDK1.8 版本，锁的粒度是 Node 节点，锁的粒度降低了。</li>\n<li>用 synchronized 代替 ReentrantLock。在锁的粒度低到这种程度的情况下，出现并发争抢的可能性也降低了。哪怕发生了争抢，自旋几十次就能拿到锁，那么 synchronized 就不会升级到重量级锁，等待的线程就不用挂起，这就减少了挂起唤醒这个上下文切换的过程开销。</li>\n</ul><h2 id=\"扩容\">扩容<a href=\"#扩容\" title=\"扩容\"></a></h2><ol><li><p>根据当前数组长度n，新建一个两倍长度的数组<code>nextTable</code>；</p>\n</li>\n<li><p>初始化<code>ForwardingNode</code>节点，其中保存了新数组<code>nextTable</code>的引用，在处理完每个槽位的节点之后当做占位节点，表示该槽位已经处理过了；</p>\n</li>\n<li><p>通过<code>for</code>自循环处理每个槽位中的链表元素，默认<code>advace</code>为真，通过CAS设置<code>transferIndex</code>属性值，并初始化<code>i</code>和<code>bound</code>值，<code>i</code>指当前处理的槽位序号，<code>bound</code>指需要处理的槽位边界;</p>\n</li>\n<li><p>在当前假设条件下，槽位a中没有节点，则通过CAS插入在第二步中初始化的<code>ForwardingNode</code>节点，用于告诉其它线程该槽位已经处理过了；</p>\n</li>\n<li><p>如果槽位a已经被线程A处理了，那么线程B处理到这个节点时，取到该节点的hash值应该为<code>MOVED</code>，值为<code>-1</code>，则直接跳过，继续处理下一个槽位b的节点；</p>\n</li>\n<li><p>处理槽位b的节点，是一个链表结构，先定义两个变量节点<code>ln</code>和<code>hn</code>，按我的理解应该是<code>lowNode</code>和<code>highNode</code>，分别保存hash值的第X位为0和1的节点，具体实现如下：使用<code>fn&amp;n</code>可以快速把链表中的元素区分成两类，A类是hash值的第X位为0，B类是hash值的第X位为1，并通过<code>lastRun</code>记录最后需要处理的节点.，通过CAS把ln链表设置到新数组的i位置，hn链表设置到i+n的位置；（见QA）</p>\n</li>\n<li><p>如果该槽位是红黑树结构，则构造树节点<code>lo</code>和<code>hi</code>，遍历红黑树中的节点，同样根据<code>hash&amp;n</code>算法，把节点分为两类，分别插入到<code>lo</code>和<code>hi</code>为头的链表中，根据<code>lo</code>和<code>hi</code>链表中的元素个数分别生成<code>ln</code>和<code>hn</code>节点，其中<code>ln</code>节点的生成逻辑如下：</p>\n<ol><li><p>如果<code>lo</code>链表的元素个数小于等于<code>UNTREEIFY_THRESHOLD</code>，默认为6，则通过<code>untreeify</code>方法把树节点链表转化成普通节点链表；</p>\n</li>\n<li><p>否则判断<code>hi</code>链表中的元素个数是否等于0：如果等于0，表示<code>lo</code>链表中包含了所有原始节点，则设置原始红黑树给<code>ln</code>，否则根据<code>lo</code>链表重新构造红黑树。</p>\n</li>\n</ol></li>\n<li><p>最后，同样的通过CAS把<code>ln</code>设置到新数组的<code>i</code>位置，<code>hn</code>设置到<code>i+n</code>位置。</p>\n</li>\n</ol><p>Q : JDK1.8扩容后 ln 和 hn 链不用经过 hash 取模运算，分别被直接放置在新数组的 i 和 n + i 的位置上，那么如何保证这种方式依旧可以用过 h &amp; (n - 1) 正确算出 hash 桶的位置？</p>\n<p>A : 如果 fh &amp; n-1 = i ，那么扩容之后的 hash 计算方法应该是 fh &amp; 2n-1 。 因为 n 是 2 的幂次方数，所以 如果 n=16， n-1 就是 1111(二进制)， 那么 2n-1 就是 11111 (二进制) 。 其实 fh &amp; 2n-1 和 fh &amp; n-1 的值区别就在于多出来的那个 1 =&gt; fh &amp; (10000) 这个就是两个 hash 的区别所在 。而 10000 就是 n 。所以说 如果 fh 的第五 bit 不是 1 的话 fh &amp; n = 0 =&gt; fh &amp; 2n-1 == fh &amp; n-1 = i 。 如果第5位是 1 的话 。fh &amp; n = n =&gt; fh &amp; 2n-1 = i+n 。</p>\n<h2 id=\"size\">size()<a href=\"#size\" title=\"size()\"></a></h2><ul><li>1.7中，刚一开始不加锁，前后计算两次所有 segment 里面的数量大小和，两次结果相等，表明没有新的元素加入，计算的结果是正确的。如果不相等，就对每个 segment 加锁，再进行计算，返回结果并释放锁。</li>\n<li>1.8中，推荐用 mappingCount 方法获取 size，返回值为 long。主要调用 sumCount方法。<ul><li>属性有 baseCount 和 counterCells。</li>\n<li>baseCount 是一个 volatile 的变量，在 addCount 方法中会使用它，而 addCount 方法在 put 结束后会调用。在 addCount 方法中，会对这个变量做 CAS 加法。</li>\n<li>CounterCell 是一种用于分配计数的填充单元，使用了 @sun.misc.Contended （防止伪共享）标记的类，内部一个 volatile 变量。</li>\n<li>在没有并发的情况下，使用一个 baseCount volatile 变量就足够了，当并发的时候，CAS 修改 baseCount 失败后，就会使用 CounterCell 类了，会创建一个这个对象，通常对象的 volatile value 属性是 1。在计算 size 的时候，会将 baseCount 和 CounterCell 数组中的元素的 value 累加，得到总的大小。</li>\n</ul></li>\n</ul>","prev":{"title":"关于Java内存区域","link":"2020/07/11/关于Java内存区域"},"next":{"title":"Tiny-Spring","link":"2020/06/19/tiny-spring"},"plink":"https://cxccao.github.io/2020/07/11/关于ConcurrentHashMap/","toc":[{"id":"关于concurrenthashmap","title":"关于ConcurrentHashMap","index":"1","children":[{"id":"先聊聊hashmap","title":"先聊聊HashMap","index":"1.1","children":[{"id":"结构","title":"结构","index":"1.1.1"},{"id":"put方法","title":"put方法","index":"1.1.2"},{"id":"get方法","title":"get方法","index":"1.1.3"},{"id":"resize方法","title":"resize方法","index":"1.1.4"}]},{"id":"concurrenthashmap如何保证线程安全？","title":"ConcurrentHashMap如何保证线程安全？","index":"1.2","children":[{"id":"jdk17","title":"JDK1.7","index":"1.2.1"},{"id":"jdk18","title":"JDK1.8","index":"1.2.2"}]},{"id":"锁粒度？","title":"锁粒度？","index":"1.3"},{"id":"扩容","title":"扩容","index":"1.4"},{"id":"size","title":"size()","index":"1.5"}]}],"copyright":{"author":"Shelton Chen","link":"<a href=\"https://cxccao.github.io/2020/07/11/关于ConcurrentHashMap/\" title=\"关于ConcurrentHashMap\">https://cxccao.github.io/2020/07/11/关于ConcurrentHashMap/</a>","updated":"2020年7月29日","license":"署名-非商业性使用-相同方式共享 4.0 国际 (<a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\" rel=\\\"external nofollow\\\" target=\\\"_blank\\\">CC BY-NC-ND 4.0</a>)"}}