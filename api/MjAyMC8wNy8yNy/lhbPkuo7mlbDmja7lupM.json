{"title":"关于数据库","date":"2020-07-27T12:41:25.000Z","date_formatted":{"ll":"2020年7月27日","L":"2020/07/27","MM-DD":"07-27"},"link":"2020/07/27/关于数据库","tags":["数据库"],"updated":"2020-07-29T08:38:56.808Z","content":"<h1 id=\"关于数据库\">关于数据库<a href=\"#关于数据库\" title=\"关于数据库\"></a></h1><h2 id=\"三大范式\">三大范式<a href=\"#三大范式\" title=\"三大范式\"></a></h2><p>高级别的范式依赖于低级别的范式</p>\n<ol><li>第一范式（1NF）：属性不可分 </li>\n<li>第二范式（2NF）：任何非主属性完全依赖于主键（不能只依赖一部分主键）</li>\n<li>第三范式（3NF）：任何非主属性不依赖其他非主属性</li>\n</ol><h2 id=\"事务\">事务<a href=\"#事务\" title=\"事务\"></a></h2><p>一组满足ACID特性的操作，可以提交事务，也可以回滚。</p>\n<ul><li>A（Atomicity）原子性：事务被视为不可分割的最小单元，事务的所有操作要么都提交成功，要么全部失败回滚。</li>\n<li>C（Consistency）一致性：数据库在事务执行前后都保持一致性状态。</li>\n<li>I（Isolation）隔离性：当多个线程并发访问数据库时，多个事务之间相互隔离，一个事务不受其他事务干扰。</li>\n<li>D（Durability）持久性：事务一经提交，修改将会永远保存到数据库汇中。即使系统崩溃也不会影响。</li>\n</ul><p>AID是操作，C是目的。</p>\n<h2 id=\"并发一致性问题\">并发一致性问题<a href=\"#并发一致性问题\" title=\"并发一致性问题\"></a></h2><ul><li>丢失修改：一个事务的更新操作被另外一个事务的更新操作覆盖。（A、B同时读到余额20元，A给余额添加10元并提交成功；B将余额减少10元并提交成功，此时余额为10元，A的操作被覆盖）。</li>\n<li>脏读：一个事务读到另一个事务未提交的数据</li>\n<li>不可重复读：一个事务多次读取同一数据的结果不一致。（A读到余额为10元，B此时修改余额为20元并提交成功，A第二次读到余额为20元，两次读取结果不一致）</li>\n<li>幻读：类似不可重复读。A读到有两笔订单，B此时添加了一笔，A第二次读到了又三笔订单，多出来的订单像是出现幻觉一样。</li>\n</ul><h2 id=\"隔离级别\">隔离级别<a href=\"#隔离级别\" title=\"隔离级别\"></a></h2><ul><li>读未提交（Read Uncommitted）：事务中的修改，即使没有提交，对其他事务也是可见的。</li>\n<li>读提交（Read Committed）：一个事务只能读取已经提交的事务所做的数据。</li>\n<li>可重复读（Repeatable Read）：同一事务中多次读取同一数据的结果是一致的。</li>\n<li>可串行化（Serializable）：事务串行执行。不会出现并发一致性问题。</li>\n</ul><div class=\"φcz\"><div class=\"φdb\"><table><thead><tr>\n<th style=\"padding:0\"></th><th align=\"center\">脏读</th><th align=\"center\">不可重复读</th><th align=\"center\">幻读</th></tr>\n</thead><tbody><tr>\n<td align=\"center\">读未提交</td><td align=\"center\">×</td><td align=\"center\">×</td><td align=\"center\">×</td></tr>\n<tr>\n<td align=\"center\">读提交</td><td align=\"center\">√</td><td align=\"center\">×</td><td align=\"center\">×</td></tr>\n<tr>\n<td align=\"center\">可重复读</td><td align=\"center\">√</td><td align=\"center\">√</td><td align=\"center\">×</td></tr>\n<tr>\n<td align=\"center\">可串行化</td><td align=\"center\">√</td><td align=\"center\">√</td><td align=\"center\">√</td></tr>\n</tbody></table></div></div><h2 id=\"mysql\">MySQL<a href=\"#mysql\" title=\"MySQL\"></a></h2><h3 id=\"索引\">索引<a href=\"#索引\" title=\"索引\"></a></h3><p>优点：可加快数据检索</p>\n<p>缺点：维护索引需要资源</p>\n<p>MySQL 索引的数据结构主要有B+树索引和哈希索引。哈希索引查询单条数据的时间复杂度为O(1)，无法用于范围查找。一般默认用 B+ 树索引。</p>\n<h4 id=\"b-tree-和-b-tree\">B Tree 和 B+ Tree<a href=\"#b-tree-和-b-tree\" title=\"B Tree 和 B+ Tree\"></a></h4><p>B Tree 是多路平衡查找树。时间复杂度为O(log n)。具体定义有，一棵M阶B Tree：</p>\n<ul><li>所有节点关键字都是按升序排列，左小右大。</li>\n<li>非叶节点的子节点数&gt;1，且&lt;=M，且M&gt;=2。</li>\n<li>非根节点关键字数量大于等于M/2。</li>\n<li>所有叶子节点在同一层。</li>\n<li>每个节点都存有索引和数据。也就是 key 和 value。</li>\n</ul><p>B+ Tree 是B Tree的升级变种。时间复杂度接近二分。</p>\n<ul><li>非叶子节点不保存数据，只保存索引。</li>\n<li>所有数据保存在叶节点。每个叶子节点都存有相邻叶子节点的指针。</li>\n</ul><p>B Tree 和 B+ Tree 的优劣：</p>\n<ul><li>B+ Tree 的层级更少：相较于 B Tree，B+ Tree 每个非叶子节点存储的关键字数更多，树的层数更少，查询速度更快。</li>\n<li>B+ Tree 的查询速度更稳定：所有数据都在叶子节点，而叶子节点又在同一层。</li>\n<li>B+ Tree 范围遍历更方便：所有叶子节点形成了有序链表，遍历时无需每一层进行遍历。</li>\n<li>B Tree 微不足道的优点是，如果访问的数据离根节点很近，那么此时 B Tree 速度会快一些。</li>\n</ul><h4 id=\"聚簇索引和非聚簇索引\">聚簇索引和非聚簇索引<a href=\"#聚簇索引和非聚簇索引\" title=\"聚簇索引和非聚簇索引\"></a></h4><h5 id=\"聚簇索引\">聚簇索引<a href=\"#聚簇索引\" title=\"聚簇索引\"></a></h5><p>按照每张表的主键构造一棵 B+ Tree，同时叶子节点中存放的就是整张表的行记录数据。这个特性决定了索引数据表中数据也是索引的一部分，每张表只能有一个聚簇索引。</p>\n<h5 id=\"非聚簇索引\">非聚簇索引<a href=\"#非聚簇索引\" title=\"非聚簇索引\"></a></h5><p>数据和索引分开。索引的叶子节点指向数据对应行。</p>\n<p>MyISAM 使用的是非聚簇索引。叶节点的data域存放的是数据记录的地址。</p>\n<p>InnoDB 使用的是聚簇索引。辅助索引的data域存放的是主键的值。所以辅助索引查找时，要走两遍。</p>\n<h5 id=\"最左前缀原则\">最左前缀原则<a href=\"#最左前缀原则\" title=\"最左前缀原则\"></a></h5><p>假设联合索引有三个字段<code>(a, b, c)</code>，那么当查询条件为<code>a</code>/<code>(a AND b)</code>/<code>(a AND b AND c)</code>时，索引才会生效。因此创建索引时尽量把查询最频繁的字段作为<strong>最左</strong>字段。</p>\n<h5 id=\"索引失效\">索引失效<a href=\"#索引失效\" title=\"索引失效\"></a></h5><ul><li>or语句前后字段没有同时拥有索引。</li>\n<li>联合索引未用左列字段</li>\n<li>like以%开头</li>\n<li>隐式类型转换（如 varchar 未加引号可能会转为 int ）</li>\n<li>where中索引列使用NOT条件（not、&lt;&gt;、!=、not、in、not exists）</li>\n<li>where中索引列使用了函数</li>\n<li>MySQL觉得全表扫描比索引快时（数据少）</li>\n</ul><h3 id=\"性能查询\">性能查询<a href=\"#性能查询\" title=\"性能查询\"></a></h3><p>使用 Explain 分析 SELECT 查询语句。</p>\n<p>常用字段有：</p>\n<ul><li>select_type：查询类型</li>\n<li>key：使用的索引</li>\n<li>rows：扫描的行数</li>\n</ul><h3 id=\"innodb-和-myisam-区别\">InnoDB 和 MyISAM 区别<a href=\"#innodb-和-myisam-区别\" title=\"InnoDB 和 MyISAM 区别\"></a></h3><ul><li>事务：InnoDB 支持事务，MyISAM 不支持。</li>\n<li>并发：InnoDB 支持行级锁，MyISAM 只支持表级锁。</li>\n<li>外键：InnoDB 支持外键，MyISAM 不支持。</li>\n<li>备份：InnoDB支持在线热备份</li>\n<li>崩溃恢复：InnoDB 崩溃后发生损坏的概率比 MyISAM 低很多，而且恢复速度也更快。</li>\n<li>其他：MyISAM支持压缩表和空间数据索引。</li>\n</ul><h3 id=\"锁算法\">锁算法<a href=\"#锁算法\" title=\"锁算法\"></a></h3><ul><li>Record Lock：锁一个记录上的索引，而不是记录本身。如果表没有设置索引，InnoDB会自动在主键上创建隐藏的聚簇索引。</li>\n<li>Gap Lock：锁定索引之间的间隙，但不包含索引本身。</li>\n<li>Next-Key Lock：是Record Lock + Gap Lock的结合；InnoDB 对于行的查询使用Next-Key Lock；解决了幻读问题。</li>\n</ul><h3 id=\"binary-log\">Binary Log<a href=\"#binary-log\" title=\"Binary Log\"></a></h3><p>Binary Log（简称 Binlog）是记录所有数据库表结构变更（如 CREATE、ALTER 等）以及表数据修改（如 INSERT、UPDATE、DELETE 等）的二进制日志。</p>\n<p>Binary Log不会记录 SELECT 这类操作，因为对数据无修改。</p>\n<h3 id=\"主从复制\">主从复制<a href=\"#主从复制\" title=\"主从复制\"></a></h3><p>主库出问题可以切换到从库、可以进行数据库层面的读写分离、可以进行日常备份。</p>\n<h4 id=\"流程\">流程<a href=\"#流程\" title=\"流程\"></a></h4><ol><li><p>Master 将变更串行写入 Binary Log 中。</p>\n</li>\n<li><p>Slave 开启一条 I/O 线程，该线程监视 Master 的 Binary Log，若有变更则写入到 自己的 Relay log中，若没有则睡眠等待。</p>\n</li>\n<li><p>Slave 开启一条 SQL 线程，监视自己的 Relay Log，若有变更则读取并执行里面的 SQL 语句。</p>\n</li>\n</ol><h3 id=\"mvcc（多版本并发控制）\">MVCC（多版本并发控制）<a href=\"#mvcc（多版本并发控制）\" title=\"MVCC（多版本并发控制）\"></a></h3><p>Multi-Version Concurrency Control</p>\n<p>用于实现<strong>读提交</strong>和<strong>可重复读</strong>这两种隔离级别。<strong>读未提交</strong>不需要 MVCC，<strong>可串行化</strong>得对所有行加锁，只用 MVCC 无法实现。</p>\n<ul><li><p>Undo Log（回滚日志）：undo log 用于存放事务提交前的数据版本，可以用于回滚，同时可以提供 MVCC 下的读。</p>\n</li>\n<li><p>Read View：用来做可见性判断。</p>\n</li>\n</ul><p>版本链。每次对记录进行更改，都会记录一条 Undo Log Record。InnoDB 在每行数据后面添加了三个字段：</p>\n<ul><li>事务ID（DB_TRX_ID）：用来表示最近一次对本行记录做修改（insert/update）的事务的标识符，即最后一次修改本行的事务ID。</li>\n<li>回滚指针（DB_ROLL_PTR）：指写入回滚段的 undo log 记录。</li>\n<li>DB_ROW_ID：随着新行插入而单调递增的行ID, 当由innodb自动产生聚集索引时，聚集索引会包括这个行ID的值，否则这个行ID不会出现在任何索引中。</li>\n</ul><p>可见性比较算法</p>\n<p>要读取的行的最后提交事务ID为TRX_ID；当前所有未提交的事务列表TRX_IDs；当前 ReadView 中最小事务ID为TRX_MIN_ID； 当前 ReadView 中最大事务ID为TRX_MAX_ID。</p>\n<p>进行 SELECT 时，根据行快照的 TRX_ID</p>\n<ul><li>TRX_ID &lt; TRX_MIN_ID，该行快照是在当前所有未提交事务之前进行更改的，可用。</li>\n<li>TRX_ID &gt; TRX_MIN_ID，该行快照是在事务启动后更改的，不可用。</li>\n<li>TRX_MIN_ID &lt;= TRX_ID &lt;= TRX_MAX_ID<ul><li>读提交（RC）：如果 TRX_ID 在 TRX_IDs 中，表示该行快照对应的事务还未提交，则该快照不可使用。否则表示已经提交，可以使用。</li>\n<li>可重复读（RR）：不可使用。</li>\n</ul></li>\n<li>在数据行快照不可使用的情况下，使用行记录的回滚指针去除 Undo Log 的版本号，将他赋值给 TRX_ID，继续进行判断。</li>\n</ul><p>读提交每次读取数据都会生成新的ReadView，而可重复读只在第一次读取数据时生成一个ReadView。</p>\n<p>推荐阅读<a href=\"https://juejin.im/post/5c9b1b7df265da60e21c0b57\" target=\"_blank\">MySQL事务隔离级别和MVCC</a></p>\n<h3 id=\"redo-log\">Redo Log<a href=\"#redo-log\" title=\"Redo Log\"></a></h3><p>重做日志。物理格式存在硬盘中。记录数据页面修改的信息。为 InnoDB 提供了持久化的能力。</p>\n<p>当修改数据页面中的信息时，流程为：</p>\n<ol><li>修改 Buffer Pool 对应页中的信息。</li>\n<li>在 Redo Log Buffer 记上一笔，此时处于 prepare 状态。</li>\n<li>写 Binary Log。</li>\n<li>Redo Log 设置成 commit 状态。</li>\n<li>返回更新结果。</li>\n</ol><p>当系统出现异常崩溃时：</p>\n<ul><li>binlog 有记录，redo log 状态 commit：正常完成事务，无需恢复</li>\n<li>binlog 有记录，redo log 状态 prepare：提交事务</li>\n<li>binlog 无记录，redo log 状态 prepare：回滚事务</li>\n<li>binlog 有记录，redo log 无记录：事务未提交，无影响</li>\n</ul><p>Redo Log Buffer 会在以下时机刷入磁盘：</p>\n<ul><li>Redo Log Buffer 空间不足时</li>\n<li>事务提交</li>\n<li>定时</li>\n<li>checkpoint 时</li>\n<li>数据库正常关闭时</li>\n</ul><p>事务提交时是否要刷入磁盘，由innodb_flush_log_at_trx_commit的值控制。</p>\n<ul><li>0：事务提交不会向硬盘同步。交由硬盘每秒刷入</li>\n<li>1：事务提交会向硬盘同步。</li>\n<li>2：事务提交会写到OS的缓冲区，OS每秒刷入硬盘</li>\n</ul><p>Redo Log 是一个环，checkpoint 之前的表示已经写到硬盘中，write_pos 指当前写的位置，write_pos 和 checkpoint 相遇时表示Redo Log 已满，此时暂停语句执行，将Redo Log 全部同步到硬盘中。</p>\n<h3 id=\"sql语句执行流程\">SQL语句执行流程<a href=\"#sql语句执行流程\" title=\"SQL语句执行流程\"></a></h3><img src=\"/2020/07/27/%E5%85%B3%E4%BA%8E%E6%95%B0%E6%8D%AE%E5%BA%93/SQL%E8%AF%AD%E5%8F%A5%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.png\" class=\"\"><h3 id=\"一条sql语句执行很慢的原因\">一条SQL语句执行很慢的原因<a href=\"#一条sql语句执行很慢的原因\" title=\"一条SQL语句执行很慢的原因\"></a></h3><ul><li>大多情况正常，偶尔慢<ul><li>数据库在刷新脏页（Redo Log 写满了、内存不够）</li>\n<li>执行时遇到锁</li>\n</ul></li>\n<li>一直很慢<ul><li>没有用上索引</li>\n<li>数据库预判错误全表扫描</li>\n</ul></li>\n</ul><h2 id=\"redis\">Redis<a href=\"#redis\" title=\"Redis\"></a></h2><p>Redis 是速度非常快的非关系型（NoSQL）内存键值数据库。常用于做缓存。</p>\n<p>优点：支持多种数据类型、可持久化、读写性能优异</p>\n<p>缺点：受单机内存大小限制，不具备容错和恢复</p>\n<h3 id=\"基本数据类型\">基本数据类型<a href=\"#基本数据类型\" title=\"基本数据类型\"></a></h3><div class=\"φcz\"><div class=\"φdb\"><table><thead><tr>\n<th align=\"center\">数据类型</th><th align=\"center\">存储值</th></tr>\n</thead><tbody><tr>\n<td align=\"center\">STRING</td><td align=\"center\">字符串、整数、浮点数</td></tr>\n<tr>\n<td align=\"center\">LIST</td><td align=\"center\">列表</td></tr>\n<tr>\n<td align=\"center\">SET</td><td align=\"center\">无序集合</td></tr>\n<tr>\n<td align=\"center\">HASH</td><td align=\"center\">包含键值对的无序散列表</td></tr>\n<tr>\n<td align=\"center\">ZSET</td><td align=\"center\">有序集合</td></tr>\n</tbody></table></div></div><h3 id=\"底层数据结构\">底层数据结构<a href=\"#底层数据结构\" title=\"底层数据结构\"></a></h3><ul><li>简单动态字符串（Simple Dynamic String，SDS）：buf[]保存字符串、len记录字符串长度、free记录buf剩余空间。</li>\n<li>链表（LinkedList）：双向链表，记录头尾节点，记录链表长度。</li>\n<li>字典（Dictht）：散列表，拉链法解决哈希冲突。<ul><li>跳跃表（SkipList）：多指针有序链表。每个节点有都有一个数组，维护前进指针和跨度。每次查找从最高层往下找。插入时丢硬币，累加正面次数，反面为止。</li>\n</ul></li>\n</ul><img src=\"/2020/07/27/%E5%85%B3%E4%BA%8E%E6%95%B0%E6%8D%AE%E5%BA%93/%E8%B7%B3%E8%B7%83%E8%A1%A8%E7%BB%93%E6%9E%84.png\" class=\"\"><ul><li>整数集合（Intset）：int16_t、int32_t、int64_t</li>\n<li>压缩列表（ZipList）：包含多个节点，每个节点可保存一个字节数组或一个整数值。</li>\n<li>快速列表（QuickList）：双向压缩列表。代替链表和压缩列表。</li>\n</ul><img src=\"/2020/07/27/%E5%85%B3%E4%BA%8E%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%BF%AB%E9%80%9F%E5%88%97%E8%A1%A8%E7%BB%93%E6%9E%84.png\" class=\"\"><h3 id=\"线程模型\">线程模型<a href=\"#线程模型\" title=\"线程模型\"></a></h3><p>Redis 内部使用文件事件处理器 <strong>File Event Handler</strong>，采用IO多路复用机制同时监听多个 socket，根据 socket 上的事件来选择对应的事件处理器进行处理。结构为四部分：</p>\n<ul><li>多个 socket</li>\n<li>IO多路复用程序</li>\n<li>文件事件分派器</li>\n<li>事件处理器</li>\n</ul><img src=\"/2020/07/27/%E5%85%B3%E4%BA%8E%E6%95%B0%E6%8D%AE%E5%BA%93/Redis%E6%96%87%E4%BB%B6%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E5%99%A8.png\" class=\"\"><p>Redis6.0 后在网络IO处理上引入了多线程，但执行命令依然是单线程。</p>\n<h3 id=\"过期时间\">过期时间<a href=\"#过期时间\" title=\"过期时间\"></a></h3><p>通过设置 key 的 expire time，可知指定 key 的存活时间。</p>\n<p>Redis 对过期 key 的删除策略是：<strong>定期删除+惰性删除</strong></p>\n<ul><li>定期删除：Redis 默认每 100ms 就随机抽取一些设置了过期时间的 key，检查是否过期，过期就删除。</li>\n<li>惰性删除：定时删除不可能把所有过期的 key 都精准删除掉，所以当我们查那个 key 时，检查是否过期，过期了就删除。</li>\n</ul><p>但是，如果过期了许多 key，我们又没有去查，导致过期的 key 太多直至耗尽内存。如何解决这个问题呢？这就需要有 Redis 内存淘汰机制。</p>\n<h3 id=\"内存淘汰机制\">内存淘汰机制<a href=\"#内存淘汰机制\" title=\"内存淘汰机制\"></a></h3><p>Redis 有 8 种淘汰机制：</p>\n<ol><li>volatile-lru：从设置过期时间的数据集中，挑出最近最少使用的淘汰</li>\n<li>volatile-lfu：从设置过期时间的数据集中，挑出最近最不经常使用的淘汰</li>\n<li>volatile-ttl：从设置过期时间的数据集中，挑出将要过期的的淘汰</li>\n<li>volatile-random：从设置过期时间的数据集中，随机淘汰</li>\n<li>allkeys-lru：从所有数据集中，挑出最近最少使用的淘汰</li>\n<li>allkeys-lfu：从所有数据集中，挑出最近最不经常使用的淘汰</li>\n<li>allkeys-random：从所有数据集中，随机淘汰</li>\n<li>no-eviction：禁止淘汰数据</li>\n</ol><h3 id=\"持久化\">持久化<a href=\"#持久化\" title=\"持久化\"></a></h3><h4 id=\"rdb\">RDB<a href=\"#rdb\" title=\"RDB\"></a></h4><p>Redis DataBase</p>\n<p>创建快照来获取存储在内存里的数据在某个时间点上的副本。</p>\n<p>RDB 是 Redis 默认的持久化方式。</p>\n<p>在 Redis.conf 配置文件中有以下设置：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">save 900 1     &#x2F;&#x2F;在900秒后，如果有1个key发生变化，则触发BGSAVE命令</span><br><span class=\"line\">save 300 10    &#x2F;&#x2F;在300秒后，如果有10个key发生变化，则触发BGSAVE命令</span><br><span class=\"line\">save 60 10000  &#x2F;&#x2F;在60秒后，如果有10000个key发生变化，则触发BGSAVE命令</span><br></pre></td></tr></table></figure><h4 id=\"aof\">AOF<a href=\"#aof\" title=\"AOF\"></a></h4><p>Append Only File</p>\n<p>Redis 将每一个收到的写命令都通过 write 函数追加到文件中。</p>\n<p>默认没有开启 AOF，需配置<code>appendonly yes</code>开启。</p>\n<p>AOF 持久化方式有三种</p>\n<ul><li>appendfsync always：每当数据更改时同步</li>\n<li>appendfsync everysec：每秒同步一次</li>\n<li>appendfsync no：由系统决定何时进行同步</li>\n</ul><p>AOF 持久化文件会变得越来越大。Redis 提供了bgrewriteaof命令，对 AOF 文件进行重写。新的 AOF 文件和原来的数据一样，但体积更小。AOF 重写并没有对旧的 AOF 进行读取，而是直接读数据库中的键值对（和快照有点像）。</p>\n<h3 id=\"事务-1\">事务<a href=\"#事务-1\" title=\"事务\"></a></h3><p>Redis 通过 MULTI、EXEC、WATCH 等命令实现事务。事务将多个命令打包，一次性，按顺序执行。在事务执行期间，服务器不会中断事务，直到处理完事务，才会去处理其他客户端的请求。</p>\n<p><strong>注：Redis 同一个事务中，命令入队，如果命令不正确，Redis 会报错，此后再进行EXEC，所有操作会回滚；当命令格式正确，因为操作数据结构引起的错误，其后的命令仍然会被执行，没有回滚。</strong></p>\n<h3 id=\"三大问题\">三大问题<a href=\"#三大问题\" title=\"三大问题\"></a></h3><h4 id=\"缓存穿透\">缓存穿透<a href=\"#缓存穿透\" title=\"缓存穿透\"></a></h4><p>访问业务系统中不存在的数据（Redis、数据库中都不存在）。</p>\n<p>如果海量请求不存在的数据，这些请求全都落在数据库中，数据库压力过大，可能崩溃。解决方案有两种。</p>\n<ol><li><p><strong>缓存空数据</strong>：将数据库查询为空的 key 缓存，后续请求直接返回 null，无需查数据库。</p>\n<p>缺点：若每次请求都是不同的 key，那 Redis 中很快就会塞满大量无效 key，而内存是有限的。</p>\n</li>\n<li><p><strong>BloomFilter 布隆过滤器</strong>：将所有可能的请求放在布隆过滤器中，请求过来时先判断是否在布隆过滤器中，存在的话才走查缓存查数据库流程，否则拒掉。</p>\n<p>原理：布隆过滤器的哈希函数对 key 进行计算，得到哈希值。根据哈希值，在 bit 数组中把对应下标置1。</p>\n<p>缺点：哈希冲突。当某个元素判断为存在时，可能误判；当判断为不存在时，一定不存在。</p>\n</li>\n</ol><h4 id=\"缓存雪崩\">缓存雪崩<a href=\"#缓存雪崩\" title=\"缓存雪崩\"></a></h4><p>缓存在某一时刻大规模失效，比如 Redis 服务器宕机了，或大批缓存同一时间失效了。解决方案：</p>\n<ol><li>采用 Redis 集群，避免单机宕机导致缓存服务失效</li>\n<li>限流，避免大量请求</li>\n<li>随机过期时间</li>\n<li>永不过期</li>\n</ol><h4 id=\"缓存击穿\">缓存击穿<a href=\"#缓存击穿\" title=\"缓存击穿\"></a></h4><p>大量并发请求同时查一个缓存中不存在的 key</p>\n<p>解决方案：</p>\n<ol><li>互斥锁，锁住第一个请求，其他请求拿不到锁阻塞，第一个请求查到数据后建缓存，释放锁，后面请求进来发现有缓存了，走缓存。</li>\n</ol>","next":{"title":"关于计算机网络","link":"2020/07/14/关于计算机网络"},"plink":"https://cxccao.github.io/2020/07/27/关于数据库/","toc":[{"id":"关于数据库","title":"关于数据库","index":"1","children":[{"id":"三大范式","title":"三大范式","index":"1.1"},{"id":"事务","title":"事务","index":"1.2"},{"id":"并发一致性问题","title":"并发一致性问题","index":"1.3"},{"id":"隔离级别","title":"隔离级别","index":"1.4"},{"id":"mysql","title":"MySQL","index":"1.5","children":[{"id":"索引","title":"索引","index":"1.5.1"},{"id":"性能查询","title":"性能查询","index":"1.5.2"},{"id":"innodb-和-myisam-区别","title":"InnoDB 和 MyISAM 区别","index":"1.5.3"},{"id":"锁算法","title":"锁算法","index":"1.5.4"},{"id":"binary-log","title":"Binary Log","index":"1.5.5"},{"id":"主从复制","title":"主从复制","index":"1.5.6"},{"id":"mvcc（多版本并发控制）","title":"MVCC（多版本并发控制）","index":"1.5.7"},{"id":"redo-log","title":"Redo Log","index":"1.5.8"},{"id":"sql语句执行流程","title":"SQL语句执行流程","index":"1.5.9"},{"id":"一条sql语句执行很慢的原因","title":"一条SQL语句执行很慢的原因","index":"1.5.10"}]},{"id":"redis","title":"Redis","index":"1.6","children":[{"id":"基本数据类型","title":"基本数据类型","index":"1.6.1"},{"id":"底层数据结构","title":"底层数据结构","index":"1.6.2"},{"id":"线程模型","title":"线程模型","index":"1.6.3"},{"id":"过期时间","title":"过期时间","index":"1.6.4"},{"id":"内存淘汰机制","title":"内存淘汰机制","index":"1.6.5"},{"id":"持久化","title":"持久化","index":"1.6.6"},{"id":"事务-1","title":"事务","index":"1.6.7"},{"id":"三大问题","title":"三大问题","index":"1.6.8"}]}]}],"copyright":{"author":"Shelton Chen","link":"<a href=\"https://cxccao.github.io/2020/07/27/关于数据库/\" title=\"关于数据库\">https://cxccao.github.io/2020/07/27/关于数据库/</a>","updated":"2020年7月29日","license":"署名-非商业性使用-相同方式共享 4.0 国际 (<a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\" rel=\\\"external nofollow\\\" target=\\\"_blank\\\">CC BY-NC-ND 4.0</a>)"}}